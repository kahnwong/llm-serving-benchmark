cpp-llamafile-start:
	./server/cpp-llamafile/Meta-Llama-3-8B-Instruct.Q4_0.llamafile
go-ollama-start:
	ollama run llama3:8b-instruct-q4_0
